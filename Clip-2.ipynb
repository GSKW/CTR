{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a73ad7c-1b9f-4009-8782-1eea4d49bb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting open_clip_torch\n",
      "  Obtaining dependency information for open_clip_torch from https://files.pythonhosted.org/packages/7c/7f/952fdffa17b15d0c7c51a730860fcf4f4982528ecc753b190dcd46cc944b/open_clip_torch-2.23.0-py3-none-any.whl.metadata\n",
      "  Downloading open_clip_torch-2.23.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: torch>=1.9.0 in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from open_clip_torch) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from open_clip_torch) (0.15.2)\n",
      "Requirement already satisfied: regex in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from open_clip_torch) (2022.10.31)\n",
      "Requirement already satisfied: ftfy in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from open_clip_torch) (6.1.1)\n",
      "Requirement already satisfied: tqdm in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from open_clip_torch) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from open_clip_torch) (0.13.2)\n",
      "Collecting sentencepiece (from open_clip_torch)\n",
      "  Downloading sentencepiece-0.1.99-cp38-cp38-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m182.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from open_clip_torch) (3.20.3)\n",
      "Requirement already satisfied: timm in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from open_clip_torch) (0.6.12)\n",
      "Requirement already satisfied: filelock in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from torch>=1.9.0->open_clip_torch) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from torch>=1.9.0->open_clip_torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from torch>=1.9.0->open_clip_torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from torch>=1.9.0->open_clip_torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from torch>=1.9.0->open_clip_torch) (3.1.2)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from ftfy->open_clip_torch) (0.2.5)\n",
      "Requirement already satisfied: requests in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from huggingface-hub->open_clip_torch) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from huggingface-hub->open_clip_torch) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from huggingface-hub->open_clip_torch) (21.3)\n",
      "Requirement already satisfied: numpy in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from torchvision->open_clip_torch) (1.23.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from torchvision->open_clip_torch) (9.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from packaging>=20.9->huggingface-hub->open_clip_torch) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from jinja2->torch>=1.9.0->open_clip_torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from requests->huggingface-hub->open_clip_torch) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from requests->huggingface-hub->open_clip_torch) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from requests->huggingface-hub->open_clip_torch) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from requests->huggingface-hub->open_clip_torch) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages (from sympy->torch>=1.9.0->open_clip_torch) (1.2.1)\n",
      "Downloading open_clip_torch-2.23.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m142.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, open_clip_torch\n",
      "Successfully installed open_clip_torch-2.23.0 sentencepiece-0.1.99\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.8 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install open_clip_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2969afee-57e2-416b-985b-b44b99e8e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import open_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86b0b0-a1d1-4de1-b07e-2f0039ab23b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-H/14', pretrained='laion2b_s32b_b79k')\n",
    "tokenizer = open_clip.get_tokenizer('ViT-H/144')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52d00e5b-c25c-4ff8-86f0-51597756cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = preprocess(Image.open(\"Cat_November_2010-1a.jpg\")).unsqueeze(0)\n",
    "text = tokenizer([\"a diagram\", \"a dog\", \"a cat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6827abb7-3017-4c8e-9215-b252d1d1e9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bolevard/.pyenv/versions/3.8.13/envs/3_8_jupyter/lib/python3.8/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da13c309-7842-4b5e-a4d4-651e4cc9360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label probs: tensor([[3.3603e-05, 9.6563e-06, 9.9996e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Label probs:\", text_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a45107c0-561d-49e9-97a2-5e43bdd2e7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (patch_dropout): Identity()\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): ModuleList(\n",
       "      (0-11): 12 x ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb43959-0d64-4970-be7b-479d50f6bd78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
